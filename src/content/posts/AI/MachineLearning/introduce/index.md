---
title: "[AI] Machine Learning(기계 학습)"
published: 2024-06-24
description: 인공지능 머신러닝에 대해서 공부하고, 어떤 방식이 있는지 알아봅니다.
image: ""
tags: [algorithm]
category: AI
draft: false
---


# [Machine Learning이란?](https://www.sap.com/korea/products/artificial-intelligence/what-is-machine-learning.html)

정의로는 인공지능의 한 분야로, 머신러닝은 인공지능의 하위 집합으로, 많은 양의 데이터를 제공하여 명시적으로 프로그래밍하지 않고 시스템이 자율적으로 학습하고 개선할 수 있게하는 방식이라고 말할 수 있습니다.

기본적으로 기계학습은 인공지능이라는 엄청 큰 집합의 하위 집합이라고 생각하시면 됩니다. 기계학습에서 알고리즘은 입력으로 들어온 dataset의 패턴과 상관관계를 찾아내고, 분석을 토대로 의사결정, 예측 등을 수행하도록 훈련됩니다.

# 기계학습의 작동방식
먼저 기계학습은 정말 다양한 알고리즘 기법을 적용하는 여러 유형의 모델로 구성됩니다.
**데이터의 특성, 목적에 따라서 지도, 비지도, 준지도, 강화학습 등 대표적 4가지 학습모델** 중 하나를 적용합니다.

머신러닝은 다양한 알고리즘 기법을 적용하는 여러 유형의 머신러닝 모델로 구성됩니다.
사용 중인 데이터 세트와 원하는 결과에 따라 각 모델 내에서 하나 이상의 알고리즘 기법을 적용할 수 있습니다.


머신러닝 알고리즘은 기본적으로 사물 분류, 패턴 발견, 결과 예측, 정보 기반 의사결정 등을 수행하도록 설계됩니다.
알고리즘은 정확도를 극대화하기 위해 여러 알고리즘을 결합할 수도 있으며, 하나만을 사용할 수도 있습니다.


:::warning[주의]
이 글은 굉장히 간단한 설명만 적혀있습니다.
자세한 학습 방법의 설명을 보고 싶다면 좀 더 세분화된 포스트로 들어가주세요.(이 글에서 예시 X)
:::
## 지도학습
지도 학습 알고리즘에서는 예시를 통해 머신을 훈련합니다.
지도 학습 모델은 '입력', '출력' 데이터 쌍으로 구성되며, 원하는 값으로 출력 레이블을 지정할 수 있습니다.

시스템은 알고리즘을 통해 시간에 따라 이 훈련 데이터를 모두 컴파일한 다음 상관관계가 있는 유사성, 차이점, 기타 논리 지점을 결정합니다. 이 작업은 인풋에 대한 답을 스스로 예측할 수 있을 때까지 반복합니다.

## 비지도학습
비지도 학습 모델에는 정답 키가 없습니다. 
머신이 입력 데이터(대부분 레이블이 없는 비정형 데이터)를 학습한 다음 관련성이 있고 액세스 가능한 데이터를 모두 사용해 패턴과 상관관계를 인식합니다.
비지도 학습은 사람이 세상을 관찰하는 방식을 기반으로 다양하게 모델링됩니다.

## 준지도학습
준지도학습은 소량의 레이블이 지정된 데이터를 입력해 레이블이 없는 데이터 세트를 증강합니다.
핵심은 레이블이 지정된 데이터를 통해 시스템이 학습 시작하며, 학습 속도와 정확성을 상당한 수준으로 개선하도록 하는 것입니다.
준지도 학습 알고리즘은 레이블이 지정된 데이터를 분석해 레이블이 없는 데이터에 적용 가능한 상관관계가 있는 속성을 찾도록 훈련합니다.



:::tip[정보]
시스템이 레이블이 지정된 데이터에 포함된 결함까지 학습해 복제할 위험이 있습니다.
준지도 학습을 가장 성공적으로 활용하는 회사에서는 선진사례 프로토콜을 구축하고 있습니다.
:::
## 강화학습

지도형 학습에서는 머신에 정답 키를 제공해 모든 올바른 결과 중에서 상관관계를 찾아 학습하도록 합니다.
강화학습에서는 정답 키는 제공되지 않지만 일련의 허용 가능한 행동, 규칙, 잠재적 최종 상태가 입력됩니다.
강화학습에서 '보상'은 숫자이며, 시스템에서 수집하려는 항목으로 알고리즘에 프로그래밍됩니다.

------------------------

이제부터 각 학습에 대한 구현과 자세한 설명을 넣은 포스트를 하도록 하겠습니다.















<!--지도 학습이란?
 

네 가지 머신러닝 모델 중 첫 번째는 지도 학습입니다. 지도 학습 알고리즘에서는 예시를 통해 머신을 훈련합니다. 지도 학습 모델은 '입력', '출력' 데이터 쌍으로 구성되며, 원하는 값으로 출력 레이블을 지정할 수 있습니다. 예를 들어 머신을 데이지꽃과 팬지꽃의 차이를 식별할 수 있도록 훈련하려고 합니다. 하나의 이진 입력 데이터 쌍에는 데이지꽃의 이미지와 팬지꽃의 이미지가 모두 포함됩니다. 해당 특정 쌍에 원하는 결과는 데이지꽃을 선택하는 것이기 때문에, 이것이 올바른 결과로서 사전 식별됩니다.

 

시스템은 알고리즘을 통해 시간에 따라 이 훈련 데이터를 모두 컴파일한 다음 상관관계가 있는 유사성, 차이점, 기타 논리 지점을 결정하기 시작하며, 이 작업은 데이지꽃인지 팬지꽃인지 묻는 질문에 대한 답을 스스로 예측할 수 있을 때까지 계속됩니다. 이는 어린 아이에게 일련의 문제를 정답 키와 함께 준 다음, 그들이 한 작업을 보여주고 논리를 설명하도록 하는 것과 같습니다. 지도형 학습 모델은 제품 추천 엔진이나 교통량 분석 앱(예: 하루 중 다른 시간대에 가장 빠른 이동 경로를 예측하는 Waze) 등 일상생활의 다양한 분야에서 사용됩니다.

 

비지도 학습이란?
 

네 가지 머신러닝 모델 중 두 번째는 비지도 학습입니다. 비지도 학습 모델에는 정답 키가 없습니다. 머신이 입력 데이터(대부분 레이블이 없는 비정형 데이터)를 학습한 다음 관련성이 있고 액세스 가능한 데이터를 모두 사용해 패턴과 상관관계를 인식하기 시작합니다. 비지도 학습은 사람이 세상을 관찰하는 방식을 기반으로 다양하게 모델링됩니다. 사람은 직관과 경험에 의존해 사물을 그룹화합니다. 어떤 사물에 대해 경험하는 예시의 수가 많을수록 그것을 분류하고 인식하는 능력이 더욱더 정확해집니다. 머신에 있어서 '경험'은 '이용 가능한 입력 데이터의 양'입니다. 비지도 학습 모델이 사용되는 대표적인 예는 안면 인식, 유전자 서열 분석, 시장 조사, 사이버 보안 등입니다.

 

준지도 학습이란?
 

네 가지 머신러닝 모델 중 세 번째는 준지도 학습입니다. 모든 데이터가 시스템에 입력되기 전에 정형화되고 레이블이 지정되어 있다면 더할 나위 없이 완벽할 것입니다. 그러나 실제에서는 이러한 일이 불가능하기 때문에, 대량의 원시 비정형 데이터를 처리해야 하는 경우 준지도 학습은 유효한 해결책이 될 수 있습니다. 이 모델은 소량의 레이블이 지정된 데이터를 입력해 레이블이 없는 데이터 세트를 증강합니다. 이 모델의 핵심은 레이블이 지정된 데이터를 통해 시스템이 학습을 시작하게 하며, 학습 속도와 정확성을 상당한 수준으로 개선하도록 하는 것입니다. 준지도 학습 알고리즘은 레이블이 지정된 데이터를 분석해 레이블이 없는 데이터에 적용 가능한 상관관계가 있는 속성을 찾도록 머신을 훈련합니다.

 

그러나 이 모델에는 이 MIT 대학출판사 보고서에서 자세히 다룬 것과 같이 시스템이 레이블이 지정된 데이터에 포함된 결함까지 학습해 복제할 위험이 있습니다. 준지도 학습을 가장 성공적으로 활용하는 회사에서는 선진사례 프로토콜을 구축하고 있습니다. 준지도 학습은 음성 및 언어 분석, 복잡한 의료 연구(예: 단백질 분류), 상위레벨 부정행위 감지에 사용됩니다.

 

강화학습이란?
 

네 가지 머신러닝 모델 중 마지막 모델은 강화학습입니다. 지도형 학습에서는 머신에 정답 키를 제공해 모든 올바른 결과 중에서 상관관계를 찾아 학습하도록 합니다. 강화학습 모델에서는 정답 키는 제공되지 않지만 일련의 허용 가능한 행동, 규칙, 잠재적 최종 상태가 입력됩니다. 알고리즘의 원하는 목표가 고정되어 있거나 양자택일인 경우 머신은 예시를 통해 학습할 수 있습니다. 그러나 원하는 목표가 변동 가능한 경우에는 경험과 보상을 통해 학습해야 합니다. 강화학습 모델에서 '보상'은 숫자이며, 시스템에서 수집하려는 항목으로 알고리즘에 프로그래밍됩니다.

 

이 모델은 여러 면에서 사람에게 체스 게임을 하는 법을 가르치는 것과 유사합니다. 체스 말이 이동할 수 있는 경우를 모두 보여주는 것은 불가능하며, 그 대신 규칙을 설명해주고 연습을 통해 기술을 습득하도록 합니다. 보상은 게임을 이기는 것뿐 아니라 상대방의 말을 획득하는 형태로 이루어집니다. 강화학습 적용 분야에는 온라인 광고 구매자의 자동 가격 입찰, 컴퓨터 게임 개발, 고위험 주식 시장 거래 등이 있습니다.


이 모델은 여러 면에서 사람에게 체스 게임을 하는 법을 가르치는 것과 유사합니다. 체스 말이 이동할 수 있는 경우를 모두 보여주는 것은 불가능하며, 그 대신 규칙을 설명해주고 연습을 통해 기술을 습득하도록 합니다. 보상은 게임을 이기는 것뿐 아니라 상대방의 말을 획득하는 형태로 이루어집니다. 강화학습 적용 분야에는 온라인 광고 구매자의 자동 가격 입찰, 컴퓨터 게임 개발, 고위험 주식 시장 거래 등이 있습니다.
-->